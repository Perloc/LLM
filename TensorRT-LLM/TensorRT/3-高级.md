![[Pasted image 20231203183934.png]]
# Dynamic Shape跨度较大时性能变差：多OptimizationProfile

要点：
1. 缩小每个Profile的shape范围，方便TensorRT自动优化
2. 推理时，根据数据形状选择相应的profile
3. 注意输入输出数据的绑定位置

多OptimizationProfile是多Context的工作基础
多OptimizationProfile会增加显存占用、引擎尺寸和plan文件尺寸

# 重叠计算和数据拷贝：多Stream

要点：
1. 使用CUDA event和CUDA stream
2. 使用pinned-memory
	1. pinned-memory：常驻内存，不可换出到硬盘，使用CUDA异步操作一定要使用pinned-memory，因为可能当执行Stream中这个操作时可能已经换出到硬盘，还得换回来，会浪费大量时间
3. 使用Async函数和*context.execute_async_v2*函数
![[Pasted image 20231203185043.png]]
# 一个engine多个线程使用：多Context

# 优化Kernel的调用，减少Launch Bound：CUDA Graph

1. 降低CPU Launch cost：将Launch工作提前完成
2. CUDA工作流优化：静态统筹Kernel调用
3. 缓解大量kernel调用时的Launch Bound
# 节约多次构建engine的时间：Timing Cache

类似引擎的序列化和反序列化，将Timing Cache保存出来供后续使用，但和plan文件一样，不能跨平台和开发环境使用

1. 优化单词引擎的构建时间，模型内多个同参数的算子不需要重复选优
2. 优化多次引擎构建（debug或参数更新后的重新构建）的时间
3. 优化同环境下多个引擎的构建时间，跨builder可用
4. 用于反复生成一模一样的引擎
# 某些Layer的算子误差较大，可以选择屏蔽吗：Algorithm Selector

1. 先通过polygraphy等工具发现某层的tactic结果不理想
2. 构造Algorithm Selector屏蔽掉该层的该tactic
	1. 实现一个*XXXAlgorithmSelector*
	2. 实现两个成员函数
		1. *select_algorithms*：用来挑选特定层的算法
		2. *report_algorithms*：用来报告所有层的挑选结果
	3. 构建网络时交给BuilderConfig
3. 构建引擎
# 更新模型权重但不重新编译引擎：Refit
# 构建期和运行期显存占用过大：Tactic Source

算子库？：cuBLAS、cuBLASLt、cuDNN
BuilderConfig中开启或关闭这些算子库可以节约部分内存和显存，并减少构建时间；但是会不能使用某些优化算子，导致性能下降甚至构建失败
# 跨硬件运行engine：Hardware compatibility和Version compatibility



